# PRELUDE: A Graph Neural Network for Inductive Drug Response Prediction

PRELUDE (Predictive Link-learning for Unseen Drug Efficacy) is a graph neural network framework designed to predict drug-cell line interactions. By constructing a heterogeneous graph of cells, drugs, and genes, PRELUDE leverages deep learning to model complex biological relationships and predict drug efficacy, with a focus on generalizing to unseen entities (inductive learning).

## Table of Contents
- [Features](#features)
- [Project Structure](#project-structure)
- [Installation and Setup](#installation-and-setup)
- [Usage](#usage)
- [Contributing](#contributing)
- [License](#license)

---
## Features
This framework incorporates several modern GNN techniques for robust link prediction:
* **Heterogeneous Graph Network**: Models cells, drugs, and genes, and the multi-relational links between them.
* **Inductive Capability**: Designed to generate predictions for nodes not seen during training.
* **Pre-trained Feature Integration**: Initializes nodes with rich, pre-trained embeddings:
    * **Cells**: A Variational Autoencoder (VAE) compresses high-dimensional gene expression data into dense embeddings.
    * **Drugs**: Uses embeddings from sources like MoleculeSTM.
    * **Genes**: Uses embeddings from sources like ESM3.
* **Data-Driven Link Curation**: Employs Gaussian Mixture Models (GMMs) to classify interactions as high-confidence positive or negative examples, creating a robust training signal.
* **Hybrid Training Objective**: Combines a supervised link prediction loss with an optional self-supervised random walk loss to learn both specific interactions and general graph topology.
* **Advanced Architectural Options**: Includes configurable options like skip connections and curriculum learning (node isolation, loss weighting).

---
## Project Structure

The repository is organized into the following key directories:
```
.
├── checkpoints/         # Stores saved model weights and training logs
├── config/             # Contains command-line argument definitions
├── data/
│   ├── embeddings/     # Source files for pre-trained node embeddings
│   ├── misc/           # Miscellaneous raw data files (e.g., drug response screens)
│   ├── processed/      # Final model-ready .dat files (generated by scripts)
│   └── raw/            # Intermediate raw link files
├── dataloaders/        # Scripts for loading graph data and features
├── models/             # GNN model and layer definitions
├── notebooks/          # Jupyter notebooks for exploration and data processing
├── scripts/            # All executable scripts for the pipeline
└── environment.yml     # Conda environment specification
```

---
## Installation and Setup

Follow these steps to set up the environment and run the project.

1.  **Clone the Repository**:
    ```bash
    git clone [https://github.com/luistafoi/PRELUDE.git](https://github.com/luistafoi/PRELUDE.git)
    cd PRELUDE
    ```

2.  **Download LFS Data**:
    This project uses Git LFS to manage large data files. Ensure Git LFS is installed, then run:
    ```bash
    git lfs pull
    ```

3.  **Create and Activate Conda Environment**:
    Use the provided `environment.yml` file to create an identical Conda environment with all necessary packages.
    ```bash
    # Create the environment from the .yml file
    conda env create -f environment.yml

    # Activate the new environment (the name is specified inside the file)
    conda activate prelude_env
    ```

---
## Usage

The project follows a multi-step workflow for data curation, preprocessing, model training, and evaluation.

### 1. Data Curation and Preprocessing (One-Time Setup)

These scripts must be run in order to transform the raw data into the final graph structure required by the model.

```bash
# Step 1.1: Use GMMs to label raw drug-cell links as positive/negative
python scripts/label_links_with_gmm.py

# Step 1.2: Build the main graph files (node.dat, link.dat) with universal IDs
python scripts/build_graph_files.py

# Step 1.3: Split the ID-based links into train, validation, and test sets
python scripts/create_splits.py

# Step 1.4: Generate the neighbor list for the GNN from the final training graph
python scripts/generate_neighbors.py
```

### 2. Model Training

Run the main training script. You can enable or disable features using command-line flags. The best performing model will be saved in the `checkpoints/` directory.

```bash
# Example: Train the full model on GPU 0 with a batch size of 1024
python scripts/train.py --gpu 0 --mini_batch_s 1024 --use_vae_encoder --use_node_isolation --use_skip_connection --use_rw_loss --use_lp_curriculum
```

### 3. Final Evaluation

Once a model is trained, use the `evaluate.py` script to get its performance on the held-out test set. **Remember to use the same feature flags you trained with.**

```bash
# Example evaluation for a model trained with skip connections and RW loss
python scripts/evaluate.py --gpu 0 --load_path checkpoints/prelude_model.pth --use_skip_connection --use_rw_loss
```

### 4. Visualizing Results

To plot the training and validation curves from a training run, use the `plot_results.py` script.

```bash
python scripts/plot_results.py checkpoints/prelude_model_log.csv
```

---
## Contributing

Contributions to the project are welcome. Please follow standard fork-and-pull-request workflows.

---
## License

This project is licensed under the Apache 2.0 License - see the `LICENSE` file for details.
